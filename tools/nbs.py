import requests
import requests_cache
import re
import json

requests_cache.install_cache()

starturl = 'https://raw.githubusercontent.com/nbs-system/php-malware-finder/master/php-malware-finder/php.yar'


def strip_last_url_path(url):
    parent, _, _ = url.rpartition('/')
    return parent



def rfetch(url):
    print("Fetching", url)

    def include(match):
        relpath = match.group(1)
        # return match.group(1)
        newurl = strip_last_url_path(url) + '/' + relpath
        # print('{} points to {}'.format(url, newurl))
        return "/* included from {} */\n".format(newurl) + rfetch(newurl)

    data = requests.get(url).text
    data = re.sub('include "([^"]+?)"\s+', include, data)
    data = re.sub('import "hash"\s*', '', data)
    return data


def parse_rules(blob):
    # produces rules and whitelist

    whitelist = set()
    rules = list()


    # private rule Drupal : Blog
    # private rule IRC
    # rule CloudFlareBypass

    tokens = re.findall('\n(?:global )?(?:private )?rule .+?\n\{\n.+?\n\}', blob, flags=re.DOTALL)

    for token in tokens:
        hashes = re.findall('== "([a-f0-9]{40})"', token)

        if 'rule IsWhitelisted' in token:
            continue

        if hashes or 'hash.sha1' in token:
            whitelist.update(hashes)
        else:
            token = token.strip()
            token = re.sub(' and not IsWhitelisted', '', token)

            rules.append(token.strip())

    return '\n'.join(rules), whitelist


def main():
    rawrules = rfetch(starturl)
    print("got {} chars of rules".format(len(rawrules)))

    with open('/tmp/nbs.yar', 'w') as fh:
        fh.write(rawrules)

    rules, whitelist = parse_rules(rawrules)

    # print("found {} rules".format(len(rules)))
    # assert rules.count('rule ') == 27
    # assert len(whitelist) == 1296, 'wrong number of whitelist'

    with open('/tmp/nbs-mwscan.yar', 'w') as fh:
        fh.write('/*\nWHITELIST = {}\n*/\n{}'.format(json.dumps(list(whitelist)), rules))

if __name__ == '__main__':
    main()
